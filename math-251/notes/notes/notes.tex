\documentclass{article}

\usepackage{amsmath,amssymb,amsthm}

\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{remark}{Remark}
\newcommand{\iso}{\tilde{=}}

\DeclareMathOperator{\im}{Im}
\DeclareMathOperator{\sgn}{sgn}
\DeclareMathOperator{\adj}{adj}

\newcommand{\F}{\mathbb{F}}

\author{Jacob Thomas Errington}
\title{Notes for Algebra II (MATH 251)}

\begin{document}

\maketitle

\section{Matrices and linear maps}

Linear maps are represented as matrices.

If $T : V \to W$ is a linear map, $B = (b_1, \cdots, b_n)$ is a basis of
$V$, and $C$ is a basis of $W$, then applying $T$ to each of the basis vectors
$b_i$ and rewriting the result in the basis $C$ gives us the column vectors for
a matrix taking vectors in $V$ and yielding vectors in $W$.

\begin{equation}
    M = \left[ [T(b_1)]_C \cdots [T(b_n)]_C \right]
\end{equation}

\subsection{Inner direct sum}

Recall the external direct sum:

\begin{equation}
    U_1 \oplus U_2 = \{(u_1, u_2) : u_1 \in U_1, u_2 \in U_2\}
\end{equation}

\begin{definition}
    If $U_1, U_2 \subset V$ are subspaces satisfying the following
    properties:
    \begin{enumerate}
        \item $U_1 + U_2 = V$, the algebraic sum of the subspaces gives the whole
            space.
        \item $U_1 \cap U_2 = \{0_V\}$, the subspaces are disjoint, except at zero.
    \end{enumerate}

    Then, $V$ is the inner direct sum of $U_1$ and $U_2$.
\end{definition}

\begin{definition}
    A linear map $T : V \to V$ is a \emph{projection} if $T^2 = T$.
\end{definition}

\begin{theorem}
    Let $V$ be a vector space over $\F$.

    \begin{enumerate}
        \item If $U, W$ are subspaces of $V$ such that $V = U \oplus W$ (inner
            direct sum) and $T : V \to V$ is a linear map such that $v \mapsto
            u$ where $v = u + w$, $u \in U, w \in W$, then $T$ is a projection
            along $W$ onto $V$.

        \item If $T : V \to V$ is a projection and $U = \im{T}$, $W = \ker{T}$,
            then $V = U \oplus W$ and $T(u+w) = u$ where $u \in U$ and $w \in
            W$.
    \end{enumerate}
\end{theorem}

\begin{proof}
    \begin{enumerate}
        \item If $u \in U$, then $u = u + 0$, so $T(u) = u$. $T(T(u + w)) =
            T(u) = u = T(u + w)$.

            $\im{T} \subset U$ and for any $u$ we have $T(u) = u$, so $U
            \subset \im{T}$. Therefore $T$ is surjective.

            $v \in \ker{T}$ if $v = 0 + w$, where $w \in W$, i.e. $v \in W$.

        \item First we check that $\im{T} + \ker{T} = V$.

            For any $v \in V$ we have that $v = T(v) + (v - T(v))$, with $T(v)
            \in \im{T}$ and $v - T(v) \in \ker{T}$. $T(v - T(v)) = T(v) -
            T(T(v)) = 0$.

            Second, we need to check that the subspaces intersect only at zero.

            Let $w \in \im{T}$, then $w = T(v) = T(T(v)) = T(w) = 0$.
    \end{enumerate}
\end{proof}

\begin{definition}
    Suppose $U \subset V$ are vector spaces, with $U$ a subspace of $V$.

    Consider $V/U = V/\tilde{}$ the \emph{quotient space} defined by
    $$
        v \tilde{} v^\prime \iff v = v^\prime + u
    $$
    for some $u \in U$.

    This is an equivalence relation. We define addition of classes with
    addition of the representatives, $[v] + [w] = [v + w]$, and scalar
    multiplication of a class by the multiplication of the representative,
    $\alpha [v] = [\alpha v]$.

    With these operations, $V/U$ is a vector space in its own right: the
    \emph{quotient space}.
\end{definition}

\begin{remark}
    The dimension of the quotien space is the difference of the dimensions of
    the involved spaces.
    $$
        \dim{V/U} = \dim V - \dim U
    $$
\end{remark}

\begin{proof}
    Consider the map $\pi : V \to V/U$ where $v \mapsto [v]$.

    \begin{align*}
        \dim V &= \dim{V/U} + \dim {\im \pi} \\
               &= \dim{V/U} + \dim U
    \end{align*}
    since the map is surjective.
\end{proof}

\begin{theorem}[Isomorphism theorem]
    Let $T : V \to W$ surjective linear map.
    $$V/\ker{T} \iso W$$
\end{theorem}

\begin{proof}
    Consider $\bar T : V/\ker{T} \to W$, where $[v] \mapsto T(v)$.

    Note that this map does not depend on the choice of representative: let
    $v^\prime \tilde{} v$, i.e. $v^\prime = v + u$, where $u \in U = \ker{T}$.
    $T(v^\prime) = T(v + u) = T(v) + T(u) = T(v)$.

    Also, $\bar T$ is linear and surjective, since $T$ is.

    $\bar T$ is injective since if $\bar T([v]) = 0$, then $T(v) = 0$ so
    $\ker{\bar T} = \{[0]\}$, $[0_V] = 0_{V/\ker{T}}$.

    Since the kernel is trivial, $\bar T$ is injective.

    Therefore, $\bar T$ is bijective, and thus an isomorphism.
\end{proof}

\section{Determinants}

\begin{definition}
    A \emph{permutation} $\sigma : \{1,\cdots,n\} \to \{1,\cdots,n\}$ is a
    bijective function denoted
    $$
        \sigma =
        \begin{array}{c c c c c}
            1 & 2 & 3 & \cdots & n \\
            \sigma(1) & \sigma(2) & \sigma(3) & \cdots & \sigma(n)
        \end{array}
    $$
\end{definition}

\begin{definition}
    A pair $(i, j)$, where $1 \leq i \leq j \leq n$ is an \emph{inversion} of a
    permutation $\sigma$ if $\sigma(i) > \sigma(j)$.
\end{definition}

\begin{definition}
    The \emph{sign} of an inversion $\sigma$, denoted $\sgn{\sigma}$, is
    $(-1)^{\# \text{ of inversions}}$.

    In other words, the sign is $1$ if the number of inversions is even, and
    $-1$ otherwise.
\end{definition}

The function
$$
    \sigma =
    \begin{array}{c c c}
        1 & 2 & 3 \\
        2 & 1 & 3
    \end{array}
$$
has one inversion, so its sign is $-1$.

\begin{definition}
    A permutation $\sigma$ is a \emph{transposition} if there are $k \neq l \in
    \{1, \cdots, n\}$ such that
    $$
        \sigma(m) =
        \begin{cases}
            i & \text{if } i \neq k, l \\
            l & \text{if } i = k \\
            k & \text{if } i = l
        \end{cases}
    $$
\end{definition}

The function given in the last example is also a transposition.


% 2 February 2015

\begin{definition}
    Let $A = (a_{ij})$ be an $n \times n$ matrix.

    The \emph{adjoint} of $A$, denoted
    $\adj A = (b_{ij})$
    is such that
    $b_{ij} = A^{ji}$,
    i.e. its entries are the corresponding cofactors in the transpose of $A$.
\end{definition}

\begin{theorem}
    The adjoint of a matrix $A$ multiplied by $A$ is equal to the identity
    matrix $Id$ up to a scaling factor precisely equal to
    $\frac{1}{\det A}$.
    \begin{equation*}
        \adj{A} A = \det{A} Id
    \end{equation*}
\end{theorem}

\end{document}
